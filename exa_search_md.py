#!/usr/bin/env python3
import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, List
import re
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client

class NewsMCPClient:
    """MCPå®¢æˆ·ç«¯ï¼Œç”¨äºè·å–æ–°é—»å¹¶å†™å…¥markdownæ–‡ä»¶"""
    
    def __init__(self, tool_name:str, url: str, arguments: str, output_dir:str):
        self.tool_name = tool_name
        self.url = url
        self.arguments = arguments
        self.output_dir = output_dir
        self.session: Optional[ClientSession] = None
        
    async def connect(self):
        """è¿æ¥åˆ°MCPæœåŠ¡å™¨"""
        try:
            print("ğŸ”— æ­£åœ¨è¿æ¥åˆ°MCPæœåŠ¡å™¨...")
            async with streamablehttp_client(self.url) as (read, write, _):
                async with ClientSession(read, write) as session:
                    self.session = session
                    await session.initialize()
                    # åˆ—å‡ºå¯ç”¨å·¥å…·
                    tools_result = await session.list_tools()
                    available_tools = [tool.name for tool in tools_result.tools]
                    print(f"âœ… è¿æ¥æˆåŠŸï¼å¯ç”¨å·¥å…·: {', '.join(available_tools)}")
                    # è·å–æ–°é—»å¹¶å¤„ç†
                    await self.get_and_process_news()
                    
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")
            raise
    
    async def get_news(self) -> List[Dict[str, Any]]:
        """è·å–æ–°é—»æ•°æ®"""
        try:
            print(f"ğŸ“° æ­£åœ¨è·å–{self.tool_name}ç±»æ–°é—»")
            result = await self.session.call_tool(
                self.tool_name,
                self.arguments
            )
            print(f"ğŸ“¡ æˆåŠŸè·å–æ–°é—»æ•°æ®")
            return json.loads(result.content[0].text) 
            
        except Exception as e:
            print(f"âŒ è·å–æ–°é—»å¤±è´¥: {str(e)}")
            return []
        
    async def add_closing_bracket(self,s: str) -> str:
        """
        å¦‚æœ `s` ä¸­å‡ºç° '('ï¼Œå°±åœ¨æœ«å°¾è¡¥é½ ')'
        """
        return s + ')' if '(' in s else s



    async def news_to_markdown(self,news_item):
        """å°†å•ä¸ªæ–°é—»æ¡ç›®è½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        metadata = [
            f"**title:** {news_item.get('title', '')}",
            f"**author:** {news_item.get('author', '')}",
            f"**publishedDate:** {news_item.get('publishedDate', '')}",
            f"**source:** {news_item.get('url', '')}",
        ]
        
        content = [
            f"\n# {news_item.get('title', '')}\n",
            "\n".join(metadata) + "\n",
        ]
        
        # æ·»åŠ å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
        if news_item.get('image'):
            content.append(f"![image]({news_item['image']})\n")
        
        # æ·»åŠ æ­£æ–‡å†…å®¹
        text = news_item.get('text', '')
        
        # æ¸…ç†Wikipediaç‰¹æœ‰çš„é“¾æ¥
        LINK_RE = re.compile(r'\(http([^)]+)\)')

        links = LINK_RE.findall(text)

        if not links:
            print("âš ï¸ è¿™ä¸ªæ–‡æœ¬é‡Œæ²¡æœ‰ Markdown é“¾æ¥")
            return "\n".join(content)
        
        # ------------------------------------------------------------
        content.extend([f"**text:**"])

        for i, url in enumerate(links, start=1):
            content.extend([f"{i}. http{await self.add_closing_bracket(url)}"])
        
        content.extend([f"-"*200," "])

        return "\n".join(content)
    
    async def get_and_process_news(self):
        """è·å–æ–°é—»å¹¶å¤„ç†çš„ä¸»è¦æµç¨‹"""
        try:
            # å®šä¹‰è¦è·å–çš„æ–°é—»ç±»åˆ«
            print(f"ğŸ”„ æ­£åœ¨å¤„ç† {self.tool_name} ç±»æ–°é—»...")
            # è·å–æ–°é—»æ•°æ®
            news_data = await self.get_news()
            results = news_data.get('results', [])
            news_count = 0
            today = datetime.now().strftime('%Y-%m-%d')

            filename = f"{self.tool_name}_{self.arguments.get("query","")}{today}.md"
            output_path = self.output_dir / filename

            with open(output_path, 'w', encoding='utf-8') as f:    
                for item in results:
                    markdown = await self.news_to_markdown(item)
                    f.write(markdown)
                    news_count += 1
                print(f"å·²ä¿å­˜{news_count}æ¡åˆ°: {output_path} ") 

        except Exception as e:
            print(f"âŒ å¤„ç†æ–°é—»æ—¶å‡ºé”™: {str(e)}")
            raise


async def main():
   
    print("ğŸš€ å¯åŠ¨MCPæ–°é—»è·å–å®¢æˆ·ç«¯...")
    tool_name = "web_search_exa"
    url = "https://mcp.exa.ai/mcp?api_key=your_api_key&profile=your_profile"
    arguments = {
        "query": "games",
        "numResults": 10
    }
    output_dir = Path("news_output")

    try:
        # åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹
        client = NewsMCPClient(tool_name, url,arguments,output_dir)
        # è¿æ¥å¹¶æ‰§è¡Œä»»åŠ¡
        await client.connect()
        print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼")
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nğŸ’¥ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
    finally:
        print("ğŸ‘‹ ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())




    

    
